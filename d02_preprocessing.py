# -*- coding: utf-8 -*-
"""Preprocessing final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ojz1pHt1gigIxHnGqSoxWyGQF4zy7Jo2
"""

# Importing Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from scipy.stats import zscore
from scipy import stats

# Loading data
from google.colab import files
import pandas as pd

# Step 1: Upload the file
uploaded = files.upload()

# Step 2: Load the file into a pandas DataFrame
# Replace 'your_file.csv' with the actual filename of the uploaded file
file_name = list(uploaded.keys())[0]  # Get the uploaded file name
print(f"Uploaded file: {file_name}")

# Load the file into a DataFrame (assuming it's a CSV file)
data = pd.read_csv(file_name)

# Step 3: Display the first few rows of the DataFrame
print("\nData Preview:")
print(data.head())

# Drop all unnamed columns
data = data.loc[:, ~data.columns.str.contains('^Unnamed')]

# Print to check correct columns
print("\nData Preview:")
print(data.head())

#Identify missing values
print("\nMissing Values:")
print(data.isnull().sum())

# Calculate missing values
missing_values = data.isnull().sum()

# Filter only columns with NaN values
missing_values = missing_values[missing_values > 0]

# Choose colors: If a column has more than 6 missing values -> orange, otherwise green
colors = ["orange" if value > 6 else "green" for value in missing_values.values]

# Plot the bar chart
plt.figure(figsize=(10, 5))
bars = plt.bar(missing_values.index, missing_values.values, color=colors)

# Add labels and title
plt.xlabel("Columns", fontsize=12)
plt.ylabel("Missing Values Count", fontsize=12)
plt.title("Missing Values per Column", fontsize=14)
plt.xticks(rotation=45)
plt.show()

#Drop rows with missing categorical values (if any)
data.dropna(subset=['mpg'], inplace=True)

#Impute missing numerical values with the mean
imputer = SimpleImputer(strategy='mean')
numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns
data[numerical_columns] = imputer.fit_transform(data[numerical_columns])

#Print values to check for missing ones after steps (we can remove this before sending the assignment it ws just to check NaN values)
print("\nMissing Values:")
print(data.isnull().sum())

#normalization min-max
scaler = MinMaxScaler()
continue_vars = ['mpg', 'displayments', 'horsepower', 'weight', 'acceleration']
data[continue_vars] = scaler.fit_transform(data[continue_vars])
print(data[continue_vars].head())

#Removing outliers using Z-score
z_scores = np.abs(stats.zscore(data[numerical_columns]))
data = data[(z_scores < 3).all(axis=1)].copy()

#Redefine features and target after outlier removal
X = data[features]

#Check distribution of Fuel Efficiency Categories for testing classes split
data['mpg_class_3'] = pd.qcut(data['mpg'], q=3, labels=['C', 'B', 'A'])
data['mpg_class_4'] = pd.qcut(data['mpg'], q=4, labels=['D', 'C', 'B', 'A'])
data['mpg_class_5'] = pd.qcut(data['mpg'], q=5, labels=['E', 'D', 'C', 'B', 'A'])

fig, axes = plt.subplots(1, 3, figsize=(15, 4))

sns.countplot(x=data['mpg_class_3'], ax=axes[0])
axes[0].set_title('3 Categories')

sns.countplot(x=data['mpg_class_4'], ax=axes[1])
axes[1].set_title('4 Categories')

sns.countplot(x=data['mpg_class_5'], ax=axes[2])
axes[2].set_title('5 Categories')

plt.show()

# Define mpg classes after outlier removal
data['mpg_class'] = pd.qcut(data['mpg'], q=4, labels=[ 'D', 'C', 'B', 'A'])
y = data['mpg_class']

print(X.dtypes)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Reset index to prevent misalignment
X_train = X_train.reset_index(drop=True)
y_train = y_train.reset_index(drop=True)

# Save processed data with aligned indices
processed_data = pd.DataFrame(X_train, columns=X_train.columns)
processed_data['mpg_class'] = y_train

# Save the file
processed_data.to_csv('processed_mpg_data.csv', index=False)

le = LabelEncoder()
y_train = le.fit_transform(y_train)
y_test = le.transform(y_test)

#Check for analysis the most Influential Features According to Random Forest Model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
feature_importance = model.feature_importances_
feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
print(feature_importance_df)

plt.figure(figsize=(8,5))
sns.barplot(x=feature_importance_df['Importance'], y=feature_importance_df['Feature'], palette='viridis')
plt.xlabel('Feature Importance')
plt.ylabel('Features')
plt.title('Feature Importance from Random Forest')
plt.show()

#Check and evaluate processed csv (we can also remove this before sending the assignment but maybe we keep it just to show we check the new file)
data = pd.read_csv('processed_mpg_data.csv')

print(data.describe)
print(data['mpg_class'].isna().sum())

#Check final distribution of mpg_class
discrete_vars = ['mpg_class']
for var in discrete_vars:
    if var in data.columns:
        plt.figure(figsize=(8, 4))
        sns.countplot(x=data[var])
        plt.title(f'Count Plot of {var}')
        plt.xlabel(var)
        plt.ylabel('Count')
        plt.show()