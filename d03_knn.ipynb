{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#D03 KNN import numpy as np import pandas as pd import warnings import\n",
    "matplotlib.pyplot as plt import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV from\n",
    "sklearn.ensemble import VotingClassifier, RandomForestClassifier from\n",
    "sklearn.neighbors import KNeighborsClassifier from sklearn.metrics\n",
    "import accuracy_score, classification_report, confusion_matrix from\n",
    "sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "warnings.filterwarnings(‘ignore’)\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "df = pd.read_csv(“processed_mpg_data.csv”)\n",
    "\n",
    "# Encode categorical target variable\n",
    "\n",
    "label_encoder = LabelEncoder() df\\[‘mpg_class’\\] =\n",
    "label_encoder.fit_transform(df\\[‘mpg_class’\\])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "\n",
    "X = df.drop(columns=\\[‘mpg_class’\\]) y = df\\[‘mpg_class’\\]\n",
    "\n",
    "# Scale features\n",
    "\n",
    "scaler = StandardScaler() X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y,\n",
    "test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Optimize KNN using GridSearchCV\n",
    "\n",
    "param_grid_knn = {‘n_neighbors’: np.arange(1, 20), ‘metric’:\n",
    "\\[‘euclidean’, ‘manhattan’, ‘minkowski’\\]} grid_search_knn =\n",
    "GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5,\n",
    "scoring=‘accuracy’) grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Get the best KNN parameters\n",
    "\n",
    "best_k = grid_search_knn.best_params\\_\\[‘n_neighbors’\\] best_metric =\n",
    "grid_search_knn.best_params\\_\\[‘metric’\\] print(f”KNN parameters:\n",
    "k={best_k}, metric={best_metric}“)\n",
    "\n",
    "# Train KNN with best parameters\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k, metric=best_metric)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Train a baseline Random Forest model for Voting Classifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Create Voting Classifier (KNN + Random Forest)\n",
    "\n",
    "voting_knn = VotingClassifier(estimators=\\[(‘KNN’, knn), (‘RF’, rf)\\],\n",
    "voting=‘hard’) voting_knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate KNN & Voting Classifier\n",
    "\n",
    "models = { “KNN”: knn, “Voting Classifier (KNN + RF)”: voting_knn }\n",
    "\n",
    "print(“Comparisons (KNN + Voting):”) for name, model in models.items():\n",
    "y_pred = model.predict(X_test) accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f”{name} Test Accuracy: {accuracy \\* 100:.2f}%“)\n",
    "\n",
    "# Generate Classification Reports\n",
    "\n",
    "print(“Reports:”) for name, model in models.items(): y_pred =\n",
    "model.predict(X_test) print(f” Classification Report:“)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix for Voting Classifier\n",
    "\n",
    "y_pred_voting = voting_knn.predict(X_test) cm = confusion_matrix(y_test,\n",
    "y_pred_voting)\n",
    "\n",
    "plt.figure(figsize=(6, 5)) sns.heatmap(cm, annot=True, fmt=‘d’,\n",
    "cmap=‘Blues’, xticklabels=label_encoder.classes\\_,\n",
    "yticklabels=label_encoder.classes\\_) plt.xlabel(“Predicted”)\n",
    "plt.ylabel(“Actual”) plt.title(“Confusion Matrix - Voting Classifier\n",
    "(KNN + RF)”) plt.show()"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
